[
{
	"uri": "/",
	"title": "AWS RDS PostgreSQL",
	"tags": [],
	"description": "",
	"content": "About the AWS RDS PostgreSQL Foundation AWS RDS PostgreSQL foundation is essential for anyone who wants to use AWS RDS PostgreSQL to build and run database-driven applications. It is also useful for anyone who wants to learn more about PostgreSQL or relational databases in general.\nAWS RDS PostgreSQL foundation topics include: Introduction Database Upgrade Performance monitoring and optimization Backup and Recovery Scalability Parameter Groups High Availability Learn more about PostgreSQL Clean Up Resources "
},
{
	"uri": "/4-backuprecovery/4-1-automatedbackups/",
	"title": "Automated Backups",
	"tags": [],
	"description": "",
	"content": "Reviewing your Instance\u0026rsquo;s Automatic Backups Let\u0026rsquo;s start by looking at the backups of the database you have created. A full database backup is taken immediately following database creation.\nOpen the Amazon RDS Console Click on rdspg-fcj-labs or the instance name you specified to reveal its details. Then select the Maintenance \u0026amp; backups tab.\nScroll down to the automated backup section and review the details. Note the backup window for the database and the latest possible restore time. Look at the available snapshots for the database. An automated snapshot from that initial database backup also appears.\n(OPTIONAL) AWS CLI Alternatively you can view the instance\u0026rsquo;s backups using the AWS CLI as shown below: AWS CLI\rAWSREGION=`aws configure get region`\r# List the automated backups for the instance\raws rds describe-db-instance-automated-backups \\\r--db-instance-identifier rdspg-fcj-labs \\\r--region $AWSREGION\r# List the snapshots for the instance\raws rds describe-db-snapshots \\\r--db-instance-identifier rdspg-fcj-labs \\\r--region $AWSREGION\r# Check the Latest Restorable Time (LRT) of the instance\raws rds describe-db-instances \\\r--db-instance-identifier rdspg-fcj-labs \\\r--query \u0026#39;DBInstances[].LatestRestorableTime\u0026#39; \\\r--region $AWSREGION \\\r--output text "
},
{
	"uri": "/2-databaseupgrade/2-1-automaticminorupgrade/",
	"title": "Automatic minor upgrade",
	"tags": [],
	"description": "",
	"content": "When you are creating the db instance you will find a checkbox that will enable automatic minor version upgrades like the following image.\nWe can find out if the option is enabled by running the following command:\nReplace your database \u0026amp; your region aws rds describe-db-instances --db-instance-identifier \u0026lt;your database name\u0026gt; --region \u0026lt;your region\u0026gt; --query \u0026#39;DBInstances[*].AutoMinorVersionUpgrade\u0026#39; Or by going to the RDS console, clicking on the db instance and select the Maintenance \u0026amp; backups tab.\nIn this case, you have not enabled Auto minor version upgrade in the first create database.\nNow, you can enable by click Modify button, then scroll down and select Enabled Auto minor version upgrade\nA PostgreSQL DB instance is automatically upgraded during your maintenance window if the following criteria are met:\nThe DB instance has the Auto minor version upgrade option enabled. The DB instance is running a minor DB engine version that is less than the current automatic upgrade minor version. "
},
{
	"uri": "/3-performancemonitoringandoptimization/3-1-cloudwatchlogsalerts/",
	"title": "CloudWatch Logs &amp; Alerts",
	"tags": [],
	"description": "",
	"content": "Viewing CloudWatch Logs When you created your database in the first lab you selected to publish logs to CloudWatch. Both the database and upgrade logs can be found in a CloudWatch Log Group associated with your database.\nAmazon CloudWatch allows us to consolidate logs from various AWS services into a single location to help draw correlations between services, like the application plane and Amazon RDS database.\nOpen CloudWatch Logs enter /aws/rds into the filter box and hit enter. Select the group assoicated with your database rds-pg-labs and take a look at the log stream.\nCreating an RDS Database Alarm Return to the Database List Click on rdspg-fcj-labs database to go to the details page. The Database detail page has a number of tabs you can look at.\nNow go to the Log \u0026amp; events tab and click on the Create alarm button. Create a new alarm as shown below.\nSend notifications : choose Yes Send notifications to : choose New email or SMS topic Topic name : fill yourname topic AvgCPU-rdspg-fcj-labs With these recipients: fill your email address Metric : choose Average of CPUUtilization Threshold : choose \u0026gt;= 15 percent Evaluation period : default setting Name of alarm : default Now go to your email client for the email address you supplied for the notification. You should receive a confirmation email within a minute or two. Confirm your subscription by clicking the link in the email. To receive the alarm email that will be generated later in the lab, you will need to confirm your subscription. You should receive a confirmation email from Amazon SNS within 90 seconds or so. Click on the link to confirm your subscription. We will be triggering this alarm in a future section\nFinally, go to AWS SNS Subscriptions to check subscriptions status "
},
{
	"uri": "/6-parametergroups/6-1-create/",
	"title": "Create Custom Parameter Group",
	"tags": [],
	"description": "",
	"content": " Go to the Amazon RDS console.\nIn the navigation pane, choose Parameter groups. Choose Create parameter group. In the Parameter group family list, select the database engine and version for your parameter group.\nIn the Type, select DB Parameter Group.\nIn the Group name, enter a name for your parameter group.\nIn the Description, enter a description for your parameter group.\nChoose Create. To verify, in the RDS menu, click on Parameter Groups either on the left hand pane or on the main RDS screen. (OPTIONAL) AWS CLI Alternatively you can create a custom parameter group using the AWS CLI as shown below:\nCode\rThe following command creates a custom parameter group:\nAWSREGION=`aws configure get region`\raws rds create-db-parameter-group \\\r--db-parameter-group-name custom-pg \\\r--db-parameter-group-family postgres15 \\\r--description \u0026#34;custom-postgres parameter group\u0026#34; \\\r--region $AWSREGION "
},
{
	"uri": "/5-scalability/5-1-create/",
	"title": "Create Read-replica to provide read scalability",
	"tags": [],
	"description": "",
	"content": "Amazon RDS Read Replicas provide enhanced performance and durability for RDS instances. They make it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create from one to 5 replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput. Read replicas can also be promoted when needed to become standalone DB instances. Find more features of RDS Read-replicas here. Amazon RDS creates a second DB instance using a snapshot of the source DB instance. It will uses the engines native asynchronous replication to update the read replica whenever there is a change to the source DB instance. The read replica operates as a DB instance that allows only read-only connections; applications can connect to a read replica just as they would to any DB instance.\nFind the RDS PostgreSQL instance rdspg-fcj-labs under the Databases menu and click on the radio button in front of the DB Instance. Click on the Actions drop down on the right side and choose Create Read Replica. For Settings, you must provide a DB Instance Identifier (i.e. the name for this instance). Something like \u0026ldquo;rdspg-fcj-labs-read\u0026rdquo; works. For the Instance Configurations and AWS Region sections, leave the default values. Uncheck the Enable storage autoscaling option. Notice that you can optionally size the Read Replica use a different instance tier than your primary instance. In your case, the Destination Region will likely be different than what you see in the screenshot and that is OK.\nFor Connectivity, leave the defaults. Leave the Network Security settings at their default.\nFor Availability, select Multi-AZ DB instance. For simplicity, we’ll leave the rest at their defaults. Scroll to the bottom and click Create read replica. It will take about 10 minutes for your read replica to be created. Your primary database continues to be available as this happens.\nOnce the Read Replica status is Available on the Databases page (you may need to use the refresh icon to see the latest Status), click on the new read replica instance. On the detail page for the read replica, first notice the endpoint. The read replica has a different endpoint than your primary instance Next, scroll down to view the replication details. You can see that our primary instance is replicating to our read replica instance. You can then connect to the read replica using its endpoint and the same username and password as the source instance. For example, connect and execute the following query to check the replication lag between the source and the replica:\nSELECT extract(epoch from now() - pg_last_xact_replay_timestamp()) AS replica_lag; RDS PostgreSQL also allows you to promote a read replica to be a standalone instance. We will do that in the next Lab.\nCongratulations: In this lab, you added a read replica instance to your configuration to provide additional read scalability to your application.\n(OPTIONAL) AWS CLI Alternatively you can create the read replica instance using the AWS CLI as shown below: Code\rThe following command creates the read replica:\nAWSREGION=`aws configure get region`\raws rds create-db-instance-read-replica \\\r--db-instance-identifier rdspg-fcj-labs-read \\\r--source-db-instance-identifier rdspg-fcj-labs \\\r--db-instance-class db.t3.medium \\\r--region $AWSREGION "
},
{
	"uri": "/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "What is AWS RDS PostgreSQL? AWS RDS PostgreSQL is a managed database service that makes it easy to set up, operate, and scale PostgreSQL databases in the cloud. RDS PostgreSQL handles all of the tasks involved in managing a PostgreSQL database, such as provisioning the hardware, configuring the database, and managing backups and restores. Benefits of using AWS RDS PostgreSQL There are many benefits to using AWS RDS PostgreSQL, including:\nEasy setup and management: RDS PostgreSQL takes care of all the tasks involved in setting up and managing a PostgreSQL database, such as provisioning the hardware, configuring the database, and managing backups and restores. This frees you up to focus on building and maintaining your applications.\\ Scalability: RDS PostgreSQL is highly scalable, making it easy to add or remove resources as needed. This is important for applications that need to handle spikes in traffic or that need to scale to meet growing demand.\nSecurity: RDS PostgreSQL provides a number of security features to protect your data, such as encryption at rest and in transit, access control lists, and auditing. This gives you the peace of mind knowing that your data is safe and secure.\\ High availability: RDS PostgreSQL offers high availability, so you can be confident that your database will be available when you need it. RDS PostgreSQL provides features such as read replicas and automatic failover to ensure that your database is always available. "
},
{
	"uri": "/7-highavailability/7-1-setup/",
	"title": "Setup high availability for RDS PostgreSQL (Multi-AZ)",
	"tags": [],
	"description": "",
	"content": "Verify Multi-AZ settings for RDS PostgreSQL Open the Amazon RDS console. Scroll to the right of the databases settings in the list for your rdspg-fcj-labs database to review its Multi-AZ configuration.\nWe could confirm that Multi-AZ was not configured, so we need to setup our database for high availability in the next section.\nSetup high availability for RDS PostgreSQL (Multi-AZ) Amazon RDS Multi-AZ deployments provide enhanced availability and durability for RDS database (DB) instances, making them a natural fit for production database workloads. When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ). Each AZ runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable. In case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby (or to a read replica in the case of Amazon Aurora), so that you can resume database operations as soon as the failover is complete. Since the endpoint for your DB Instance remains the same after a failover, your application can resume database operation without the need for manual administrative intervention. More details can be seen here.\nTo configure RDS PostgreSQL instance for High availability we need to modify the instance. Select rdspg-fcj-labs instance and press the Modify button on top.\nIn the Modify DB Instance: rdspg-fcj-labs page, scroll down to the Availability \u0026amp; durability section and make sure to select Create a standby instance (recommended for production usage). Scroll to the bottom and click on Continue. On the next window you will notice that the attribute Multi-AZ deployment is changed to Yes in the New Value column. In the Scheduling of modifications section select Apply immediately and click Modify DB Instance at the bottom. Now the instance will change to Modifying status and we need to wait until this operation completes - this usually takes ~5-10 mins.\nWhen status become Available again, click on the rdspg-fcj-labs instance identifier to review its settings. So we configured our RDS PostgreSQL instance for high availability and in the next section we will test this capability.\n(OPTIONAL) AWS CLI Alternatively you can convert the instance to Multi-AZ using the AWS CLI as shown below: Code\rThe following command converts the instance to Multi-AZ.\nAWSREGION=`aws configure get region`\raws rds modify-db-instance \\\r--db-instance-identifier rdspg-fcj-labs \\\r--multi-az \\\r--apply-immediately \\\r--region $AWSREGION "
},
{
	"uri": "/7-highavailability/7-2-connect/",
	"title": "Connect to the Multi-AZ endpoint",
	"tags": [],
	"description": "",
	"content": "RDS PostgreSQL does provide customers an option to simulate the AZ failure and High Availability by offering the option to reboot the Postgres Instance with the failover option. This option will initiate AZ level failover for the Instance, the instance on the secondary AZ will become primary, and the instance on the primary will become the new secondary.\nIn the terminal window EC2 instance, enter and run these commands to showcase connection to the database at 10-second intervals: while true;\rdo\rpsql -h rdspg-fcj-labs.cssuddr073hp.us-east-1.rds.amazonaws.com -U masteruser pglab; echo -e \u0026#34;\\n\\n\u0026#34;\rsleep 10\rdone Observe the output below. This output shows you the current IP address of the RDS PostgreSQL primary instance. In the next task, we will cause a failover and observe the change in the IP address as the primary instance changes. For now, leave this window open and let the command loop run. Proceed to the next task. Configure Event subscription for Failover event To be notified about Failover events (or other ones) we create RDS Event subscription for this lab.\nOpen the Amazon RDS console and choose Event Subscriptions in the left pane.\nClick Create event subscription. We use an email subscription in this example - to get notifications over the email you provide: And choose rdspg-fcj-labs instance from the list or use the All instances option, and select the Failover event type: Before you can start receiving the event notifications via email you will need to verify your email address. You should receive a verificaiton email shortly after creating the subscription. (OPTIONAL) AWS CLI Alternatively you can create an Event Subscription using the AWS CLI as shown below:\nCode\rThe following code snippet creates an SNS Topic and an RDS Event Subscription with the same.\nAWSREGION=`aws configure get region`\r# Create an SNS Topic for the Event Subscription\rSNSTOPICARN=$(aws sns create-topic \\\r--name rdspg-fcj-email \\\r--region $AWSREGION \\\r--output text)\r# Subscribe the given E-mail ID to the SNS Topic\raws sns subscribe \\\r--topic-arn $SNSTOPICARN \\\r--protocol email \\\r--no-return-subscription-arn \\\r--notification-endpoint fcj@gmail.com \\\r--region $AWSREGION\r# Create the RDS Event Subscription\raws rds create-event-subscription \\\r--subscription-name subscr-rdspg-fcj-labs \\\r--sns-topic-arn $SNSTOPICARN \\\r--source-type db-instance \\\r--event-categories failover \\\r--source-ids rdspg-fcj-labs \\\r--region $AWSREGION \\\r--enabled "
},
{
	"uri": "/3-performancemonitoringandoptimization/3-2-createsomedbactivity/",
	"title": "Create some DB Activity",
	"tags": [],
	"description": "",
	"content": "Create some DB Activity Using MobaXterm to connect to your app server which you created at workshop 1\nThen run the following command to generate some activity on your RDS instance.\npgbench -i --fillfactor=90 --scale=500 --host=rdspg-fcj-labs.cssuddr073hp.us-east-1.rds.amazonaws.com --username masteruser pglab This will create a new database called pglab on the PostgreSQL server at rdspg-fcj-labs.cssuddr073hp.us-east-1.rds.amazonaws.com and populate it with 500 times the size of the default test data set. The test data will be inserted using a fill factor of 90%, which means that each page of the database will be filled to 90% capacity before moving on to the next page.\nOnce the pgbench command begins you can move on to the next session.\n"
},
{
	"uri": "/2-databaseupgrade/",
	"title": "Database Upgrade",
	"tags": [],
	"description": "",
	"content": "\rThis chapter assumes you have already created an RDS PostgreSQL instance in the first worshop.\nThis lab will take you through the upgrade process of an RDS PostgreSQL instance.\nThis lab contains following tasks: Automatic minor upgrade Upgrading the engine version Validate the upgrade process "
},
{
	"uri": "/4-backuprecovery/4-2-modifybackups/",
	"title": "Modify Backups",
	"tags": [],
	"description": "",
	"content": "Adjusting your backup window \u0026amp; backup retention Next we will change the backup window to 22:30 (UTC) and set the backup retention to 3 days.\nIn the upper right of the database details screen choose the Modify button On the Mondify DB Instance page, scroll down to the backup section which is under \u0026ldquo;Additional Configuraiton\u0026rdquo; section. Using the pull down menu change the backup retention period to 3 days. The maximium retention period for automated backups is 35 days. Manual snapshots can be retained indefinetly\nUpdate the backup window to occur at 22:30 (UTC), so plan accordingly Once you\u0026rsquo;ve made the appropriate changes click the continue button. Confirm the modifications on the next screen and choose the Apply immediately option. Click Modify DB Instance As the changes are being applied you\u0026rsquo;ll be taken back to the database instance details page. Note: the exact start time of the backup will be chosen at random within the 30 minute window.\n(OPTIONAL) AWS CLI Alternatively you can modify the instance\u0026rsquo;s backup window using the AWS CLI as shown below:\nAWS CLI\rAWSREGION=`aws configure get region`\raws rds modify-db-instance \\\r--db-instance-identifier rds-pg-labs \\\r--preferred-backup-window 22:00-22:30 \\\r--apply-immediately \\\r--region $AWSREGION "
},
{
	"uri": "/6-parametergroups/6-2-modify/",
	"title": "Modify Custom Parameter Group",
	"tags": [],
	"description": "",
	"content": "To modify a parameter group in Amazon RDS, you can use the AWS Console, the AWS CLI, or the AWS SDK.\nUsing the AWS Console:\nGo to the Amazon RDS console.\nIn the navigation pane, choose Parameter groups.\nChoose the parameter group that you want to modify.\nUnder Actions, choose Edit. In the filter parameters search box, look for log_connections parameter. Click on the drop down in the Values column (if needed you can check the box to the left to activate the Values drop down). Change the value to 1 and click Save changes.\nNow clear the search box and look for another parameter by entering log_min_duration_statement. In the Values box, enter 4000. Click Save changes.\nNote if you get an error message like “ Error saving: This parameter group cannot be modified because it is currently being applied to DB Instance” please wait a few minutes and retry your save action.\nClick the checkbox against the new parameter group and go to Parameter group actions drop down (on top right), choose Compare. Verify the changes from the default parameter group and then click Close. (OPTIONAL) AWS CLI Alternatively you can modify a custom parameter group using the AWS CLI as shown below: Code\rThe following command modifies a custom parameter group:\nAWSREGION=`aws configure get region`\raws rds modify-db-parameter-group \\\r--db-parameter-group-name custom-pg \\\r--parameters \u0026#34;ParameterName=\u0026#39;log_connections\u0026#39;,ParameterValue=1,ApplyMethod=immediate\u0026#34; \u0026#34;ParameterName=\u0026#39;log_min_duration_statement\u0026#39;,ParameterValue=4000,ApplyMethod=immediate\u0026#34; \\\r--region $AWSREGION "
},
{
	"uri": "/5-scalability/5-2-promote/",
	"title": "Promote Read Replica into standalone instance",
	"tags": [],
	"description": "",
	"content": "You can use read replica promotion as a data recovery scheme if the source DB instance fails in case of Single-AZ instance configuration. This approach complements synchronous replication, automatic failure detection, and failover.\nIn the event of a failure, do the following:\nPromote the read replica. Direct database traffic to the promoted DB instance. Create a replacement read replica with the promoted DB instance as its source. Open the Amazon RDS console , choose your rdspg-fcj-labs-read instance.\nWe need to check that Replica Lag is close to zero to minimize the data loss of missing transactions from the primary instance. When we are sure that lag is minimal, we return to the RDS Console, choose the replica instance and start the Promotion: in the Actions menu choose Promote: In the Settings page, you can leave the defaults such as Enable automated backups and click on Promote Read Replica. The promotion process can take several minutes or longer to complete, depending on the size of the read replica. The replica instance will get into the Modifying state during that time.\nAfter that, the replica becomes available again and is shown as a standalone instance. (OPTIONAL) AWS CLI Alternatively you can promote the read replica using the AWS CLI as shown below: Code\rThe following command creates the read replica:\nAWSREGION=`aws configure get region`\raws rds promote-read-replica \\\r--db-instance-identifier rdspg-fcj-labs-read \\\r--backup-retention-period 1 \\\r--region $AWSREGION "
},
{
	"uri": "/2-databaseupgrade/2-2-upgradingtheengineversion/",
	"title": "Upgrading the engine version",
	"tags": [],
	"description": "",
	"content": "Minor version upgrades include only changes that are backward-compatible with existing applications.\nIf your PostgreSQL DB instance is using Read Replicas, you must upgrade all of the read replicas before upgrading the source instance. You could follow the same instructions below, but apply them first to read replicas.\nIf your DB instance is in a Multi-AZ deployment, both the writer and standby replicas are upgraded. Your DB instance might not be available until the upgrade is complete.\nLet\u0026rsquo;s upgrade our database instance now.\nIn the navigation pane, choose Databases, and then choose the DB instance that you want to upgrade.\nChoose Modify. The Modify DB Instance page appears. For DB engine version, choose the new version. Choose Continue and check the summary of modifications. To apply the changes immediately, choose Apply immediately. Choosing this option can cause an outage in some cases.\nOn the confirmation page, review your changes. If they are correct, choose Modify DB Instance to save your changes. You can see your instance being upgraded by going back to the RDS instances page. (OPTIONAL) AWS CLI Alternatively you can upgrade the instance using the AWS CLI as shown below: AWS CLI\rThe following command upgrades the instance to version 15.4.\r```\raws rds modify-db-instance --db-instance-identifier \u0026lt;your database name\u0026gt; --engine-version 15.4 --apply-immediately --region \u0026lt;your region\u0026gt;\r```\r"
},
{
	"uri": "/6-parametergroups/6-3-apply/",
	"title": "Apply Custom Parameter Group",
	"tags": [],
	"description": "",
	"content": "We are now going to apply this custom parameter group to our primary and replica instances.\nClick on the Databases menu on the left and select the radio button next to rdspg-fcj-labs and click on Modify at the top.\nScroll down to Additional Configuration-\u0026gt;Database options and choose the custom parameter group that you previously created in your account (e.g. custom-pg) as shown below. Scroll down to the bottom and click on Continue.\nIn the next section, choose Apply Immediately as shown below. Select the radio button next to the DB identifier rdspg-fcj-labs as shown below and verify that the Status of the database is Modifying. Certain parameter changes require a reboot of the RDS instance, hence you can verify if a reboot is required by selecting the primary instance rdspg-fcj-labs and under the Configuration tab, on the bottom left against the modified parameter group (custom-pg) you will see a Pending reboot written indicating a need for the instance to be rebooted in order for the changes to be applied. ( The same can be verified for the replica instance too. ) So, you will have to reboot instances for the Parameter group to become active ( In-sync ).\nBy selecting the database rdspg-fcj-labs, and by going under the Configuration tab, you can now see after rebooting the instance, the parameter group dispalys to be In Sync. (OPTIONAL) AWS CLI Alternatively you can apply the custom parameter group using the AWS CLI as shown below: Code\rThe following command applies the custom parameter group.\nAWSREGION=`aws configure get region`\r# Modify the instance and change the parameter group\raws rds modify-db-instance \\\r--db-instance-identifier rdspg-fcj-labs \\\r--db-parameter-group-name custom-pg \\\r--apply-immediately \\\r--region $AWSREGION\r# Reboot the instance aws rds reboot-db-instance \\\r--db-instance-identifier rdspg-fcj-labs \\\r--region $AWSREGION You can optionally verify the parameter changes from psql command line. To do so, connect to the instance :\npsql -h rdspg-fcj-labs.cssuddr073hp.us-east-1.rds.amazonaws.com -U masteruser pglab Then run the following commands\nshow log_connections;\rshow log_min_duration_statement; The ouput would look like below:\nCongratulations, you\u0026rsquo;ve made it to the end of the Parameter Groups lab.\n"
},
{
	"uri": "/4-backuprecovery/4-3-manualsnapshots/",
	"title": "Manual Snapshots",
	"tags": [],
	"description": "",
	"content": "Taking a manual backup of your database. In addition to automated databsae backups, there are often times when you want to take an explicit backup of the database, just ahead of a major software release, or to refresh your staging enviornment. With AWS RDS these backups are called manual snapshots. RDS creates a storage volume snapshot of your DB instance, backing up the entire DB instance and not just individual databases. They are stored in Amazon S3 but they are not in a customer accessible bucket.\nWith your instance selected from the list of databases . Select Actions -\u0026gt; Take Snapshot On the Take DB Snapshot screen, enter a name for your snapshot (e.g. manual-snapshot-rdspg-fcj-labs) and click Take Snapshot. As the snapshot is creating, you will be taken to the Snapshots page in the AWS RDS Console. Let\u0026rsquo;s go to the list of databases and take a look at the instance status. You should see its backing up. Once the database status returns to available return to the list of snapshots . Review all the snapshot details by scrolling to the right. (OPTIONAL) AWS CLI Alternatively you can take a manual snapshot of the instance using the AWS CLI as shown below:\nAWS CLI\rThe following command takes a manual snapshot of the instance.\nAWSREGION=`aws configure get region`\raws rds create-db-snapshot \\\r--db-instance-identifier rdspg-fcj-labs \\\r--db-snapshot-identifier manual-snapshot-rdspg-fcj-labs \\\r--region $AWSREGION "
},
{
	"uri": "/7-highavailability/7-3-perform/",
	"title": "Perform failover to verify high availability",
	"tags": [],
	"description": "",
	"content": "RDS PostgreSQL does provide customers an option to simulate the AZ failure and High Availability by offering the option to reboot the PostgreSQL Instance with the failover option. This option will initiate AZ level failover for the instance - the instance in the secondary AZ will become primary, and the instance in the primary will become the new secondary.\nOpen the Amazon RDS console and choose your rdspg-fcj-labs instance. Click on the Actions drop down on the right side and choose Reboot. Make sure to check the Reboot With Failover option, and click Reboot. Next, click on the Logs \u0026amp; Events tab to check the status of the failover. Observe the change in the events as the failover goes through various steps. Now, go back to the EC2 instance terminal window, where the while loop command is still running. You will notice the change in the IP address as shown below. You will also notice a brief notice of interruption right around the time of failover. Afer that the database instance becomes available again and activity against the database completes successfully. Also note that RDS endpoint has started resolving to a new IP address (from another AZ)\n(Note: In your lab the IP will be different).\nYou will also see the status and AZ in the Amazon RDS service console update as the failover happens but there may be a short delay before the console status and AZ are refreshed.\n(OPTIONAL) AWS CLI Alternatively you can reboot the instance with failover using the AWS CLI as shown below:\nCode\rThe following command reboots the instance with failover.\nAWSREGION=`aws configure get region`\raws rds reboot-db-instance \\\r--db-instance-identifier rdspg-fcj-labs \\\r--region $AWSREGION \\\r--force-failover "
},
{
	"uri": "/5-scalability/5-3-perform/",
	"title": "Perform vertical scaling",
	"tags": [],
	"description": "",
	"content": " Open the Amazon RDS console.\nChoose the rdspg-fcj-labs instance and click Modify.\nOn the Modify DB Instance page - choose the appropriate DB instance class or DB instance size:. Then click Continue\nOn Summary of modifications notice the changed istance type and choose Apply immediately to apply the changes and click on Modify DB instance.\nThe instance will start the DB instance class upgrade process, that could take 10-15 minutes, after which you should see in the RDS Console the updated instance class:\n(OPTIONAL AWS CLI) Alternatively you can scale up the instance using the AWS CLI as shown below: Code\rThe following command modifies the instance class of the instance.\nAWSREGION=`aws configure get region`\raws rds modify-db-instance \\\r--db-instance-identifier rds-pg-labs \\\r--db-instance-class db.t3.large \\\r--apply-immediately \\\r--region $AWSREGION "
},
{
	"uri": "/3-performancemonitoringandoptimization/",
	"title": "Performance monitoring",
	"tags": [],
	"description": "",
	"content": "\rThis chapter assumes you have already created an RDS PostgreSQL instance in the first worshop.\nMonitoring the health and preformance of your database is an important task. In this lab, you will configure an automated alert for one of your database performance metrics. Then you will run a generated workload against your Postgres database. From there you will view the performance metrics in the RDS Console and analyze the metrics using the RDS Performance Insights tool.\nAmazon RDS provides CloudWatch metrics for your database instances at no additional charge. You can use the RDS Management Console to view key operational metrics, including compute/memory/storage capacity utilization, I/O activity, and instance connections. Amazon RDS also provides Enhanced Monitoring, which provides access to over 50 metrics, including CPU, memory, file system, and disk I/O; and Performance Insights, an easy-to-use tool that helps you quickly detect performance problems.\nThis lab contains following tasks: CloudWatch Logs \u0026amp; Alerts Create some DB Activity Reviewing Performance Database Load Test Make your Load Test run faster "
},
{
	"uri": "/3-performancemonitoringandoptimization/3-3-reviewingperformance/",
	"title": "Reviewing Performance",
	"tags": [],
	"description": "",
	"content": "Now that we have a workload running against our AWS RDS PostgreSQL database, we can take a look at the metrics and dashboards available in CloudWatch and dive deeper with Performance Insights.\nIn the [RDS Console(https://console.aws.amazon.com/rds/home#databases)] , navigate to the Database instance details page for your database. To view CloudWatch metrics, click on the Monitoring tab. Explore various charts. You can click on the chart area of an individual chart to bring the chart full screen and get access to different chart customizations. To view Enhanced monitoring metrics, click on the Monitoring dropdown on the right side of the screen and pick Enhanced monitoring and explore various charts. Now look for the Performance Insights link in the RDS console. Right-click on the link and open up Performance Insights in a new browser tab. Select your database instance and you will notice the load being generated on your RDS instance Explore different waits in Performance Insights Next we will put a heavy load on the database and revisit these dashboards.\n"
},
{
	"uri": "/2-databaseupgrade/2-3-validatetheupgradeprocess/",
	"title": "Validate the upgrade process",
	"tags": [],
	"description": "",
	"content": "After a few minutes you will see that the database already finished the upgrade process and the status will be back to Available.\nClick on the instance, then the Configuration tab and you will see that the database engine version went from 15.3 to 15.4.\nOr if you rather use the CLI command, type in the console:\naws rds describe-db-instances --db-instance-identifier \u0026lt; your database name \u0026gt; --region \u0026lt; your region \u0026gt; --query DBInstances[*].EngineVersion You can see engine version after run command above:\n"
},
{
	"uri": "/4-backuprecovery/",
	"title": "Backup and Recovery",
	"tags": [],
	"description": "",
	"content": "\rThis chapter assumes have already created an RDS PostgreSQL instance in the first workshop.\nUnderstanding how your database is backed up and options for recovery are critically important before moving database workloads to the cloud. In this lab will take a look at the backup and recovery functions available in RDS for PostgreSQL.\nThis lab contains following tasks: Automated Backups Modify Backups Manual Snapshots Restore Snapshot Point in Time Restore AWS Backup "
},
{
	"uri": "/3-performancemonitoringandoptimization/3-4-databaseloadtest/",
	"title": "Database Load Test",
	"tags": [],
	"description": "",
	"content": "Data load test Performance under stress Now let’s run a stress-test transactional workload on the RDS database instance. This workload will open up 200 connections to your database and each of those connections will continuously make updates to the tables. To launch the transactional workload, go back to the AWS CLI and run this command:\npgbench --host \u0026lt;your database endpoint\u0026gt;--username masteruser --protocol=prepared -P 30 --time=300 --client=200 --jobs=200 \u0026lt;your dabatase name\u0026gt; This will start 200 concurrent client sessions that will execute the pgbench benchmark workload against the database specified by the parameter. The benchmark will run for 300 seconds, and the results will be printed to the terminal.\nLet\u0026rsquo;s revisit some of the dashboards we looked at in the earlier section.\nStart by looking at the monitoring tab for the database. You will see some variation in the data with the load test running, for instance you should now see a large increase in the number of database connections. Let\u0026rsquo;s also take a look at Performance Insights and explore the various charts as our 200 user stress-test runs.\nCounter metrics Database load Top SQL Notice that in the above example, there is a large sky blue area on the Database load graph. The sky blue area corresponds to a large number of database sessions that are waiting on the WALWriteLock \u0026amp; DataFileReadevent.\nFrom a performance optimization standpoint, if we can figure out how to reduce the number of sessions waiting on the WALWriteLock \u0026amp; DataFileRead event, our workload can run faster.\nYou can learn more about Performance Insights here .\nCheck your email. You should have received an email notification about the CPU Utilization alert you setup earlier in this lab. "
},
{
	"uri": "/5-scalability/5-4-migrating/",
	"title": "Migrating to a Multi-AZ DB cluster using a read replica",
	"tags": [],
	"description": "",
	"content": "Amazon RDS Read Replicas provide enhanced performance and durability for RDS instances. They make it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create from one to 5 replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput. Read replicas can also be promoted when needed to become standalone DB instances. Find more features of RDS Read-replicas here .\nTo migrate a Single-AZ deployment or Multi-AZ DB instance deployment to a Multi-AZ DB cluster deployment with reduced downtime, you can create a Multi-AZ DB cluster read replica. Please visit Working with Multi-AZ DB cluster read replicas for additional details.\nAmazon RDS creates a second DB instance using a snapshot of the source DB instance. It will uses the engines\u0026rsquo; native asynchronous replication to update the read replica whenever there is a change to the source DB instance. The read replica operates as a DB instance that allows only read-only connections; applications can connect to a read replica just as they would to any DB instance.\nTo migrate a Single-AZ deployment or Multi-AZ DB instance deployment to a Multi-AZ DB cluster deployment with reduced downtime, you can create a Multi-AZ DB cluster read replica.\nFind RDS PostgreSQL instance rdspg-fcj-labs under the Databases menu and click on the radio button in front of the DB Instance. Click on the Actions drop down on the right side and choose Create Read Replica. For Settings, you must provide a DB Instance Identifier (i.e. the name for this instance). For the Availability section, select Multi-AZ DB Cluster - new deployment option. For simplicity, we’ll leave the rest at their defaults. Scroll to the bottom and click Create read replica\nAfter you click Create read replica, you’ll be taken back to the Databases page. Click the refresh icon to refresh the page and you should see the read replica being created. It will take about 10 minutes for your read replica to be created. Your primary database continues to be available as this happens.\nOnce the Read Replica status is Available on the Databases page ( you may need to use the refresh icon to see the latest Status ), click on the new read replica instance. On the detail page for the Multi-AZ DB replica cluster, first notice the endpoint(s). The replica has a different endpoint(s) than your primary instance. Next, scroll down to view the replication details. You can see that our primary instance is replicating to our read replica instance. You can then connect to the read replica using its endpoint and the same username and password as the source instance. For example, connect and execute the following query to check the replication lag between the source and the replica:\nSELECT extract(epoch from now() - pg_last_xact_replay_timestamp()) AS replica_lag; You can also promote this Multi-AZ read replica cluster to a stand-alone cluster. We will do that in the next step.\nClick on Actions, and select Promote to detach and promote the rdspg-fcj-labs-read-test Multi-AZ DB Cluster by selecting Promote read replica It will take about 1-2 minutes for your read replica to be detached and promoted as an independent RDS DB Cluster with Multi-AZ DB Cluster deployment option.\nAt this point, you have successfully migrated your RDS PostgreSQL instance with Multi-AZ DB Instance deployment mode to the RDS PostgreSQL Multi-AZ DB Cluster deployment option.\nCongratulations: In this lab, you added a Multi-AZ DB Cluster read replica instance to your configuration to migrate your application/database from Multi-AZ DB Instance deployment option to the Multi-AZ DB Cluster deployment option.\n(OPTIONAL) AWS CLI Alternatively you can promote the read replica using the AWS CLI as shown below: Code\rThe following command creates the read replica:\nARN=`aws rds describe-db-instances --db-instance-identifier rdspg-fcj-labs --query \u0026#39;DBInstances[].DBInstanceArn\u0026#39; --output text --region $AWSREGION`\raws rds create-db-cluster \\\r--db-cluster-identifier rdspg-fcj-labs-read-test \\\r--engine postgres \\\r--replication-source-identifier $ARN \\\r--db-cluster-instance-class db.r5d.large \\\r--storage-type io1 --iops 1000 \\\r--region $AWSREGION aws rds promote-read-replica-db-cluster \\\r--db-cluster-identifier rdspg-fcj-labs-read-test "
},
{
	"uri": "/4-backuprecovery/4-4-restoresnapshot/",
	"title": "Restore Snapshot",
	"tags": [],
	"description": "",
	"content": "Restoring from manual snapshot Database backups are of very little value unless they can be used to restore the database. In this section we will take the manual snapshot just created and restore the PostgreSQL database.\nSelect the snapshot you created in the prior section from the list and select Actions, then click Restore Snapshot When restoring from a snapshot, a NEW RDS database instance is created, the original instance will continue to run normally\nComplete the Restore DB Instance page using the defaults except for the DB Instance Identifier where you can enter rdspg-fcj-labs-restore-manual-snapshot, Select db.t3.meidum as instance type and then select the Restore DB Instance at the bottom of the form. As the restore initiates you are taken to the list of databases. You can monitor the status of the restoration and refresh the list until the restored database\u0026rsquo;s status is Available.\n(OPTIONAL) AWS CLI Alternatively you can restore an instance from a manual snapshot using the AWS CLI as shown below:\nAWS CLI\rThe following command takes a manual snapshot of the instance.\nAWSREGION=`aws configure get region`\raws rds restore-db-instance-from-db-snapshot \\\r--db-instance-identifier rdspg-fcj-labs-restore-manual-snapshot \\\r--db-snapshot-identifier manual-snapshot-rdspg-fcj-labs \\\r--db-instance-class db.t3.medium \\\r--region $AWSREGION "
},
{
	"uri": "/5-scalability/5-5-multiazdbcluster/",
	"title": "Creating a DB instance read replica from a Multi-AZ DB cluster",
	"tags": [],
	"description": "",
	"content": "Amazon RDS Read Replicas provide enhanced performance and durability for RDS instances. They make it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create a DB instance read replica from a Multi-AZ DB cluster in order to scale beyond the compute or I/O capacity of the cluster for read-heavy database workloads. You can direct this excess read traffic to one or more DB instance read replicas. You can also use read replicas to migrate from a Multi-AZ DB cluster to a DB instance.\nPlease visit Working with Multi-AZ DB cluster read replicas for additional details.\nA DB instance read replica of a Multi-AZ DB cluster is different than the reader DB instances of the Multi-AZ DB cluster in the following ways:\nThe reader DB instances act as automatic failover targets, while DB instance read replicas do not. Reader DB instances must acknowledge a change from the writer DB instance before the change can be committed. For DB instance read replicas, however, updates are asynchronously copied to the read replica without requiring acknowledgement. Reader DB instances always share the same instance class, storage type, and engine version as the writer DB instance of the Multi-AZ DB cluster. DB instance read replicas, however, don’t necessarily have to share the same configurations as the source cluster. You can promote a DB instance read replica to a standalone DB instance. You can’t promote a reader DB instance of a Multi-AZ DB cluster to a standalone instance. The reader endpoint only routes requests to the reader DB instances of the Multi-AZ DB cluster. It never routes requests to a DB instance read replica. For more information, see Overview of Multi-AZ DB clusters.\nTo create a read replica, specify a Multi-AZ DB cluster as the replication source. One of the reader instances of the Multi-AZ DB cluster is always the source of replication, not the writer instance. This condition ensures that the replica is always in sync with the source cluster, even in cases of failover.\nFind RDS PostgreSQL instance rdspg-fcj-labs-read-test under the Databases menu and click on the radio button in front of the DB Instance. Click on the Actions drop down on the right side and choose Create Read Replica. For Settings, you must provide a DB Instance Identifier (i.e. the name for this instance). For the Availability section, select Multi-AZ DB instance deployment option. For simplicity, we’ll leave the rest at their defaults. Scroll to the bottom and click Create read replica.\nAfter you click Create read replica, you’ll be taken back to the Databases page. Click the refresh icon to refresh the page and you should see the read replica being created.\nIt will take about 10 minutes for your read replica to be created. Your primary database continues to be available as this happens\nOnce the Read Replica status is Available on the Databases page (you may need to use the refresh icon to see the latest Status), click on the new read replica instance. On the detail page for the read replica, first notice the endpoint. The read replica has a different endpoint than your primary instance.\nNext, scroll down to view the replication details. You can see that our primary cluster is replicating to our read replica instance.\nYou can then connect to the read replica using its endpoint and the same username and password as the source cluster. For example, connect and execute the following query to check the replication lag between the source and the replica:\nSELECT extract(epoch from now() - pg_last_xact_replay_timestamp()) AS replica_lag; Congratulations: In this lab, you added a Multi-AZ DB Instance read replica instance to your Multi-AZ DB Cluster configuration for scaling out read workload.\n(OPTIONAL) AWS CLI Alternatively you can promote the read replica using the AWS CLI as shown below: Code\rThe following command creates the read replica:\naws rds create-db-instance-read-replica \\\r--db-instance-identifier taz-maz-replica \\\r--source-db-cluster-identifier rdspg-fcj-labs-read-test "
},
{
	"uri": "/3-performancemonitoringandoptimization/3-5-makeyourloadtestrunfaster/",
	"title": "Make your Load Test run faster",
	"tags": [],
	"description": "",
	"content": " In this extra credit exercise, we will show you how to make your pgbench transactional workload faster. By faster, we mean we want to complete more transactions in the same amount of overall time. To do so, we will need to identify potential bottlenecks and fix them.\nFirst, let’s identify our current baseline showing the number of transactions per second our pgbench workload performed. Go to your MobaXterm window and look at how many tps (transactions per second) it reported for the 200 user pgbench load test you ran in the last module. In the last two lines of the screenshot above, we see that our transactional workload was able to do approximately 578 transactions per second (tps). This is our baseline. The 578 tps was done on an db.t3.medium instance. If your lab environment uses a different instance type, such as the db.t3.medium, you may see a different value.\nNow, let\u0026rsquo;s analyze our performance. In general, you can look at database performance through both a micro and macro lens. At a micro level, you want to look at individual SQL statements and identify if any individual SQL statement is a candidate to be tuned. Performance Insights is a good tool for this kind of micro level analysis.\nAt a macro level, you want to look at performance metrics for the overall system. You do this to see if any of the key resources (such as CPU or Memory or IO) are being heavily taxed and becoming a bottleneck. The Monitoring metrics in the RDS Console (which are also available in AWS CloudWatch) are a good tool for this.\nLet\u0026rsquo;s begin by starting with the micro level and looking at our workload in Performance Insights. If we zoom into the time period of the workload (you can select a custom time period by dragging across a range of times in the Database Load chart), we can notice that our top wait event is WALWriteLock and DataFileRead. We identified this as our top wait event because we can visually see that it occupies the most area in our chart—in other words, it has the most number of sessions waiting on this event (an average of 100 database sessions are waiting on that event). We can also identify that the SQL Statement that is associated with the WALWriteLock is END, which in PostgreSQL is the statement that closes/commits the transaction.\nCounter metrics Database load Top SQL You may not be familiar with the WALWriteLock wait event. The WAL is the Write Ahead Log, also known as the transaction journal. These files contain a persistent record of COMMITs and COMMITs can not return to the client until the WAL information is safely written to disk.\nIn our case, it looks like a large number of our 200 database sessions are backing up on the WALWriteLock and these sessions are waiting on this event when their transaction ENDs (commits). In other words, the system appears that it is not able to write the commits to disk fast enough.\nLet\u0026rsquo;s now look at the macro level. To do so, navigate to the RDS Console and go to the Monitoring tab for your database. This will show us some system-wide metrics. Here is an example of what you will see: In the above chart, notice that CPUUtilization is not high even though we have 200 simultaneous connections on a 2 vCPU shape (db.t3.medium). So, we can say that it does not appear that CPU is a bottleneck.\nNext look at some of the I/O metrics. In the chart above, notice that our DiskQueueDepth of waiting I/O requests has gotten large. Also, notice that our Write IOPS is close to 1000. If you remember from when we created the database, we decided to use Provisioned IOPS (io1) storage with 1000 IOPS (if you forgot, you can see the current specification for your storage under the Configuration tab. Look for the Storage Type and IOPS fields). So, it is looking like we might be hitting the current limits of our allocated storage. As a final confirmation, you can also page through the charts and find the Write Latency chart:\nIn the WriteLatency chart, we can see that the write latencies got very high during our workload. This kind of behavior would be inline with our hypothesis that we are hitting the limits of our configured storage (1000 IOPS), which causes the queue depth and write latencies to increase, and which causes writes to the WAL to take longer, and which causes more and more database sessions to have to wait longer and longer for the WAL to be written when they commit their transaction.\nSo, it looks like we can make our transactional workload run faster if we increase the IOPS. The good news is that the storage used by RDS is elastic. You can increase/decrease the IOPS configuration while the database runs. You can even change the Storage Type (from io1 to gp2 or vice-versa) while the database runs if you wanted.\nLet’s modify our database and specify 3500 IOPS (up from its current value of 1000). To do so, click the Modify button at the top of the screen. On the modification screen, change the Provisioned IOPS field to 3500.\nThen scroll down to the bottom of the modification page and click Continue.\nOn the Summary and Scheduling page, be sure to choose Apply Immediately. Then click Modify DB Instance.\nAt this point, I suggest you go to the Databases List . The nice thing about the Databases List page is that it is easy to refresh the page so that you can track the changes in the Status. What you want to do is watch the Status while RDS changes the IOPS. The database will remain open while this happens. But we want to wait for the change to complete before we run our workload again. The process will take 10-15 minutes. You will see the status first say Modifying and then it will say Storage Optimization as the backend storage system optimizes itself to deliver on the new IOPS configuration.\n(OPTIONAL) AWS CLI Alternatively you can modify the IOPS of the instance using the AWS CLI as shown below: Command\rThe following command modifies the IOPS of the instance.\naws rds modify-db-instance --db-instance-identifier rds-pg-labs --iops 3500 --allocated-storage 100 --apply-immediately --region \u0026lt; your region \u0026gt; Once the status returns to Available (or if you are impatient, wait at least until it says “Storage Optimization”), then return to Cloud9 and re-run the same workload as before:\npgbench --host \u0026lt;your database endpoint\u0026gt;--username masteruser --protocol=prepared -P 30 --time=300 --client=200 --jobs=200 \u0026lt;your dabase name\u0026gt; You should now see that the benchmark runs faster. For example, you should now see approximately 1300 transactions per second (up from 578 transactions per second before).\nSo, by increasing the IOPS capacity of the storage, you were able to make this stress test transactional workload run faster. You are not limited to just using the RDS/CloudWatch metrics and Performance Insight. You can extend the default CloudWatch metrics with custom ones . You can use other PostgreSQL tools like the Dashboards built into pgAdmin. Or some PostgreSQL DBAs like to use the tool pgBadger to analyze database performance. To learn about how to use pgBadger with RDS PostgreSQL, read this .\nIn this workshop, We are using db.t3.mdedium instance type for handle labs. So, we might also see a large number of wait events for DataFileRead. The DataFileRead wait event could indicate that your instance type might not have enough memory to fit the working dataset into the database shared buffers. So, you could consider switching to an instance type with more memory as one possible way to address the DataFileRead waits.\n"
},
{
	"uri": "/4-backuprecovery/4-5-pointintimerestore/",
	"title": "Point in Time Restore",
	"tags": [],
	"description": "",
	"content": "Recover your database to a point in time Sometimes you will want to restore the database to a particular point in the past, just prior to running a data conversion script that encountered errors, or to refresh your stage environment to a state before an upgrade script was run. This is called a Point In Time Recovery or PITR.\nAmazon RDS for PostgreSQL allows restore to any point in time during your backup retention period. This is possible through the use of automated backups in combination with transaction logs, which are uploaded to S3 every 5 minutes.\nSo far in this section of the lab we have used the AWS Management Console for our tasks. You also can administer your RDS PostgreSQL instance from the command line using the AWS CLI. To demostrate this we will use the command-line interface for this particular lab.\nAmazon RDS keeps track of the latest restorable time for your database. We will lookup this information using the AWS-CLI. To run these commands we will use the Cloud9 enviornment you setup in the prerequisties section. If you haven\u0026rsquo;t done this, return here and complete this step.\nUsing your EC2 instances, lookup the latest restore time for your database.\naws rds describe-db-instances \\\r--db-instance-identifier rdspg-fcj-labs \\\r--region $AWSREGION \\\r--query \u0026#39;DBInstances[0].LatestRestorableTime\u0026#39; \\\r--output text Sample output below shows a latest restore time of Octorber 6, 2023 at 14:04 UTC\n2023-10-6T12:04:19Z Using the AWS-CLI we can use the following command to restore the database to the latest restorable time we looked up in the prior step. Be sure to update the time.\naws rds restore-db-instance-to-point-in-time \\\r--source-db-instance-identifier rdspg-fcj-labs \\\r--target-db-instance-identifier rdspg-fcj-labs-restore-latest \\\r--restore-time 2023-10-6T12:04:19Z You will see output similar to: Output\r\u0026#34;DBInstance\u0026#34;: {\r\u0026#34;PubliclyAccessible\u0026#34;: true,\r\u0026#34;MasterUsername\u0026#34;: \u0026#34;masteruser\u0026#34;,\r\u0026#34;MonitoringInterval\u0026#34;: 0,\r\u0026#34;LicenseModel\u0026#34;: \u0026#34;postgresql-license\u0026#34;,\r\u0026#34;VpcSecurityGroups\u0026#34;: [\r{\r\u0026#34;Status\u0026#34;: \u0026#34;active\u0026#34;,\r\u0026#34;VpcSecurityGroupId\u0026#34;: \u0026#34;sg-040ccaea808501fad\u0026#34;\r}\r],\r\u0026#34;CopyTagsToSnapshot\u0026#34;: false,\r\u0026#34;OptionGroupMemberships\u0026#34;: [\r{\r\u0026#34;Status\u0026#34;: \u0026#34;pending-apply\u0026#34;,\r\u0026#34;OptionGroupName\u0026#34;: \u0026#34;default:postgres-15\u0026#34;\r}\r],\r\u0026#34;PendingModifiedValues\u0026#34;: {},\r\u0026#34;Engine\u0026#34;: \u0026#34;postgres\u0026#34;,\r\u0026#34;MultiAZ\u0026#34;: false,\r\u0026#34;DBSecurityGroups\u0026#34;: [],\r\u0026#34;DBParameterGroups\u0026#34;: [\r{\r\u0026#34;DBParameterGroupName\u0026#34;: \u0026#34;default.postgres15\u0026#34;,\r\u0026#34;ParameterApplyStatus\u0026#34;: \u0026#34;in-sync\u0026#34;\r}\r],\r\u0026#34;PerformanceInsightsEnabled\u0026#34;: false,\r\u0026#34;AutoMinorVersionUpgrade\u0026#34;: true,\r\u0026#34;PreferredBackupWindow\u0026#34;: \u0026#34;22:30-23:00\u0026#34;,\r\u0026#34;DBSubnetGroup\u0026#34;: {\r\u0026#34;Subnets\u0026#34;: [\r{\r\u0026#34;SubnetStatus\u0026#34;: \u0026#34;Active\u0026#34;,\r\u0026#34;SubnetIdentifier\u0026#34;: \u0026#34;subnet-0b17d2e34c1123500\u0026#34;,\r\u0026#34;SubnetOutpost\u0026#34;: {},\r\u0026#34;SubnetAvailabilityZone\u0026#34;: {\r\u0026#34;Name\u0026#34;: \u0026#34;us-east-1e\u0026#34;\r}\r},\r{\r\u0026#34;SubnetStatus\u0026#34;: \u0026#34;Active\u0026#34;,\r\u0026#34;SubnetIdentifier\u0026#34;: \u0026#34;subnet-0cf079d239ac29e77\u0026#34;,\r\u0026#34;SubnetOutpost\u0026#34;: {},\r\u0026#34;SubnetAvailabilityZone\u0026#34;: {\r\u0026#34;Name\u0026#34;: \u0026#34;us-east-1b\u0026#34;\r}\r},\r{\r\u0026#34;SubnetStatus\u0026#34;: \u0026#34;Active\u0026#34;,\r\u0026#34;SubnetIdentifier\u0026#34;: \u0026#34;subnet-0bee38e5233fa9f09\u0026#34;,\r\u0026#34;SubnetOutpost\u0026#34;: {},\r\u0026#34;SubnetAvailabilityZone\u0026#34;: {\r\u0026#34;Name\u0026#34;: \u0026#34;us-east-1f\u0026#34;\r}\r},\r{\r\u0026#34;SubnetStatus\u0026#34;: \u0026#34;Active\u0026#34;,\r\u0026#34;SubnetIdentifier\u0026#34;: \u0026#34;subnet-06327d061c2b4587b\u0026#34;,\r\u0026#34;SubnetOutpost\u0026#34;: {},\r\u0026#34;SubnetAvailabilityZone\u0026#34;: {\r\u0026#34;Name\u0026#34;: \u0026#34;us-east-1a\u0026#34;\r}\r},\r{\r\u0026#34;SubnetStatus\u0026#34;: \u0026#34;Active\u0026#34;,\r\u0026#34;SubnetIdentifier\u0026#34;: \u0026#34;subnet-0cd302225e2bf84ca\u0026#34;,\r\u0026#34;SubnetOutpost\u0026#34;: {},\r\u0026#34;SubnetAvailabilityZone\u0026#34;: {\r\u0026#34;Name\u0026#34;: \u0026#34;us-east-1d\u0026#34;\r}\r},\r{\r\u0026#34;SubnetStatus\u0026#34;: \u0026#34;Active\u0026#34;,\r\u0026#34;SubnetIdentifier\u0026#34;: \u0026#34;subnet-0b05e234776e32206\u0026#34;,\r\u0026#34;SubnetOutpost\u0026#34;: {},\r\u0026#34;SubnetAvailabilityZone\u0026#34;: {\r\u0026#34;Name\u0026#34;: \u0026#34;us-east-1c\u0026#34;\r}\r}\r],\r\u0026#34;DBSubnetGroupName\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;VpcId\u0026#34;: \u0026#34;vpc-05136ed012ff6cc5d\u0026#34;,\r\u0026#34;DBSubnetGroupDescription\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;SubnetGroupStatus\u0026#34;: \u0026#34;Complete\u0026#34;\r},\r\u0026#34;ReadReplicaDBInstanceIdentifiers\u0026#34;: [],\r\u0026#34;AllocatedStorage\u0026#34;: 100,\r\u0026#34;DBInstanceArn\u0026#34;: \u0026#34;arn:aws:rds:us-east-1:478371912360:db:rdspg-fcj-labs-restore-latest\u0026#34;,\r\u0026#34;BackupRetentionPeriod\u0026#34;: 3,\r\u0026#34;DBName\u0026#34;: \u0026#34;pglab\u0026#34;,\r\u0026#34;PreferredMaintenanceWindow\u0026#34;: \u0026#34;thu:08:05-thu:08:35\u0026#34;,\r\u0026#34;DBInstanceStatus\u0026#34;: \u0026#34;creating\u0026#34;,\r\u0026#34;IAMDatabaseAuthenticationEnabled\u0026#34;: false,\r\u0026#34;EngineVersion\u0026#34;: \u0026#34;15.3\u0026#34;,\r\u0026#34;MaxAllocatedStorage\u0026#34;: 1000,\r\u0026#34;DeletionProtection\u0026#34;: false,\r\u0026#34;DomainMemberships\u0026#34;: [],\r\u0026#34;StorageType\u0026#34;: \u0026#34;io1\u0026#34;,\r\u0026#34;DbiResourceId\u0026#34;: \u0026#34;db-YZM6TLDJKUBUM3MFXZIGZ5AGGM\u0026#34;,\r\u0026#34;CACertificateIdentifier\u0026#34;: \u0026#34;rds-ca-2019\u0026#34;,\r\u0026#34;Iops\u0026#34;: 1000,\r\u0026#34;StorageEncrypted\u0026#34;: true,\r\u0026#34;AssociatedRoles\u0026#34;: [],\r\u0026#34;KmsKeyId\u0026#34;: \u0026#34;arn:aws:kms:us-east-1:478371912360:key/dd420e91-002c-49bc-89d8-709cecce145a\u0026#34;,\r\u0026#34;DBInstanceClass\u0026#34;: \u0026#34;db.t3.medium\u0026#34;,\r\u0026#34;DbInstancePort\u0026#34;: 0,\r\u0026#34;DBInstanceIdentifier\u0026#34;: \u0026#34;rdspg-fcj-labs-restore-latest\u0026#34;\r} Now, let\u0026rsquo;s return to the RDS Console to check the restoring database. If you look at the details, note all the database specifications (e.g. DB Instance Class, Security Group) match the original database. Now we will use the RDS Console to restore our database to 30 minutes prior. Select the rdspg-fcj-labs database, choose Actions, and select Restore to point in time. On the Launch DB Instance page, choose a custom and select a time 30 minutes prior. Enter a new DB instance identifier (e.g. rdspg-fcj-labs-earlier-restore), leave the remaining information at default values and click on Restore to point in time. As the restore begins you will be take back to the list of databases and should see your new instance being created. "
},
{
	"uri": "/5-scalability/",
	"title": "Scalability",
	"tags": [],
	"description": "",
	"content": "Scalability is the ability of a system to handle increasing amounts of data and traffic without impacting performance. Amazon RDS PostgreSQL offers a variety of scalability options, including:\nVertical scaling: Increasing the size of your DB instance class can provide more CPU, memory, and I/O capacity. Horizontal scaling: Adding read replicas to your DB instance can distribute read traffic across multiple instances and improve performance. Aurora: Amazon RDS Aurora is a fully managed, MySQL- and PostgreSQL-compatible relational database that is built for the cloud. Aurora offers high scalability and performance, and it is also highly available. In this lab, you will add a read replica instance to your configuration to provide additional read scalability to your application. And simulate read-replica failover scenario.\nThis lab contains following tasks: Create Read-replica to provide read scalability Promote Read Replica into standalone instance Perform vertical scaling Migrating to a Multi-AZ DB cluster using an inbound read replica Multi-AZ DB Cluster outbound read replica "
},
{
	"uri": "/4-backuprecovery/4-6-awsbackup/",
	"title": "AWS Backup",
	"tags": [],
	"description": "",
	"content": "AWS Backup is a fully managed backup service that makes it easy to centralize and automate the backing up of data across AWS services. With AWS Backup, you can create backup policies called backup plans. You can use these plans to define your backup requirements, such as how frequently to back up your data and how long to retain those backups.\nAWS Backup lets you apply backup plans to your AWS resources by simply tagging them. AWS Backup will automatically backs up your AWS resources according to the backup plan that you defined.\nRDS/PostgreSQL will automatically backup your database and retain those backups for the length of your retention period, up to 35 days. Backups preformed via AWS Backup are considered manual snapshots, and will persist until deleted.\nCreating a Service Role for AWS Backup In order for AWS Backup to preform operations on your behalf we need to assign it a service role.\nFrom the IAM Console select Create role Select AWS Service for the trusted entity type and use the use cases dropdown to find and select AWS Backup, select the AWS Backup radio button, then click Next. In the add permissions step, use the filter by entering AWSBackupServiceRole and select the checkboxes for: AWSBackupServiceRolePolicyForBackup and AWSBackupServiceRolePolicyForRestore, then click Next. Give the role a name, rdspg-AWSBackupServiceRole, review the details then click Create Role. On-Demand Backup from AWS Backup Begin in the AWS Backup Console .\nFirst create a Backup Vault, which is a logical container used to organize your backups. Click on Backup Vaults from the left-hand menu, then select Create Backup vault. Give the vault a name, rdspg-backup-vault and click Create Backup vault. With your vault created you can now create an on-demand backup. Choose Protected resources from the left-hand menu, then click Create on-demand backup. Complete the dialog by selecting RDS and your resource type then choosing the rdspg-fcj-labs database. Select the backup vault you just created. Select choose an IAM role, and select your rdspg-AWSBackupServiceRole from the dropdown and finally hit Create on-demand backup. You will see the backup in your backup jobs list. This is the same as the manual snapshot, but your backup is organized into a backup vault. Setup a Backup Plan in AWS Backup Selection of resources from a backup plan can be done using either resource tags or direct references.\nNow setup a backup plan using resource tags. Using AWS Backup this way will ensure that newly created resources that are properly tagged with be backed up via AWS Backup\nBegin by adding resource tags to your database from the RDS Console , click the rdspg-fcj-labs instance, then select the tags tab and choose Add. Add Environment for production and ResourceType for rdspg-fcj tag to your rdspg-fcj-labs database.\nFrom the AWS Backup Console select Backup plans from the left-hand menu, then choose Create backup plan. Select Build new plan, enter Backup plan name rdspg-backup-plan, enter Backup rule name DailyBackups, select Backup vault rdspg-backup-vault, leaving everything else at the default, then click Create plan. Complete the dialog by entering the resource assignment name, rdspg-bp-resource-selection, choose IAM role and select the IAM role created earlier rdspg-AWSBackupServiceRole. Finally add the Environment and ResoureType tags as shown in the screengrab. Congratulations! Now that you have created a backup plan based on tags, any databases you create in future with these tags will be automatically backed up with this plan.\n"
},
{
	"uri": "/6-parametergroups/",
	"title": "Parameter Groups",
	"tags": [],
	"description": "",
	"content": "Parameter groups are a collection of engine configuration values that you set for your Amazon Relational Database Service (RDS) database instance. They can be used to configure a wide range of database settings, such as memory allocation, logging level, and connection pooling.\nParameter groups are useful for a variety of purposes, including:\nConsistency: Parameter groups can help you to ensure that all of your database instances are configured in the same way. This can help to reduce the risk of errors and make it easier to troubleshoot problems. Performance tuning: Parameter groups can be used to tune your database for specific workloads. For example, you can increase the memory allocation for a database that is running heavy read workloads. Security: Parameter groups can be used to implement security best practices. For example, you can disable certain features that are not needed for your application. Here are some tips for using parameter groups effectively:\nUse the default parameter groups as a starting point, but modify them to meet the specific needs of your application. Create custom parameter groups for different types of database instances, such as production instances and development instances. Test any changes to parameter groups in a staging environment before deploying them to production. Monitor your database instances to ensure that the parameter groups are configured correctly. This lab contains the following tasks Create Custom Parameter Group Modify Custom Parameter Group Apply Custom Parameter Group "
},
{
	"uri": "/7-highavailability/",
	"title": "High Availability",
	"tags": [],
	"description": "",
	"content": "High availability (HA) for Amazon RDS PostgreSQL can be achieved using a variety of methods, including:\nMulti-AZ deployments: Multi-AZ deployments create a standby replica of the database in a different Availability Zone (AZ) than the primary database. If the primary database fails, the standby replica can be promoted to the primary database, minimizing downtime. Read replicas: Read replicas are copies of the database that can be used to offload read traffic from the primary database. This can improve the performance and scalability of the database. Read replicas can also be used to create a disaster recovery plan in case the primary database fails. Database clusters: Database clusters are a group of database instances that work together as a single logical unit. Clustered databases can be used to achieve high availability and scalability by distributing the workload across multiple instances. Multi-AZ deployments are the most common way to achieve high availability for Amazon RDS PostgreSQL. Multi-AZ deployments are easy to set up and manage, and they provide a high level of availability.\nRead replicas can also be used to improve the availability of Amazon RDS PostgreSQL databases. Read replicas can be used to offload read traffic from the primary database, which can improve the performance and scalability of the database. Read replicas can also be used to create a disaster recovery plan in case the primary database fails.\nDatabase clusters are the most advanced option for achieving high availability and scalability for Amazon RDS PostgreSQL. Database clusters are more complex to set up and manage than multi-AZ deployments, but they can provide a higher level of availability and scalability.\nIn this lab, you will setup the high-availability Multi-AZ configuration for your RDS PostgreSQL database instance. Then you will simulate a failover event to see how it performs. Finally, you scale-up your RDS instance for additional write capacity.\nThis lab contains following tasks: Setup high availability for RDS PostgreSQL (Multi-AZ) Connect to the Multi-AZ endpoint Perform failover to verify high availability "
},
{
	"uri": "/8-learnmoreaboutpostgresql/",
	"title": "Learn more about PostgreSQL",
	"tags": [],
	"description": "",
	"content": "Benechmarking PostgreSQL Server Pgbench is a benchmarking tool that is included in the PostgreSQL distribution. It is used to test the performance of PostgreSQL servers under a variety of workloads. Pgbench can be used to test a wide range of factors, including:\nTransaction throughput Latency Memory usage CPU usage Disk I/O Pgbench works by creating a number of concurrent client sessions that execute a series of SQL statements. The SQL statements are typically representative of the types of transactions that are executed in a real-world application. Pgbench then measures the performance of the PostgreSQL server under the load generated by the client sessions.\nPgbench can be used to test a variety of workloads, including:\nTPC-B: A benchmark that simulates a complex online transaction processing (OLTP) workload. TPROC: A benchmark that simulates a simple OLTP workload. TPC-C: A benchmark that simulates a warehouse management system workload. Custom workloads: Pgbench can also be used to test custom workloads by specifying a script file that contains the SQL statements to be executed. To run pgbench, you simply need to specify the following parameters:\nThe number of concurrent client sessions The duration of the benchmark test The database to connect to The transaction script to use Pgbench will then generate a report that shows the performance of the PostgreSQL server under the load generated by the client sessions. The report will include the following metrics:\nTransactions per second (tps): The average number of transactions that were completed per second. Latency: The average time it took to complete a transaction. Memory usage: The amount of memory that was used by the PostgreSQL server during the benchmark. CPU usage: The amount of CPU time that was used by the PostgreSQL server during the benchmark. Disk I/O: The amount of disk I/O that was performed by the PostgreSQL server during the benchmark. Here are some tips for using pgbench for newbies:\nStart with a simple benchmark: If you are new to pgbench, it is best to start with a simple benchmark, such as the TPROC benchmark. This will help you to get familiar with the tool and to learn how to interpret the results. Use a small number of clients: It is also best to start with a small number of concurrent client sessions when running pgbench benchmarks. You can then gradually increase the number of clients to see how the performance of the PostgreSQL server changes under load. Monitor the performance of the PostgreSQL server: When running pgbench benchmarks, it is important to monitor the performance of the PostgreSQL server. You can use tools such as pgAdmin or pgBouncer to monitor metrics such as CPU usage, memory usage, and disk I/O. Analyze the results: Once you have run a pgbench benchmark, it is important to analyze the results. This will help you to identify any performance bottlenecks and to make changes to improve the performance of the PostgreSQL server. Now, We will explain in this workshop:\npgbench -i --fillfactor=90 --scale=500 --host=rdspg-fcj-labs.cssuddr073hp.us-east-1.rds.amazonaws.com --username masteruser pglab -i: *creates four tables pgbench_accounts, pgbench_branches, pgbench_history, and pgbench_tellers, destroying any existing tables of these names. -f (\u0026ndash;fillfactor=90): Specifies that the test data should be inserted using a fill factor of 90%. This means that each page of the database will be filled to 90% capacity before moving on to the next page. -s (\u0026ndash;scale=500): Specifies that the test data should be scaled to 500 times the size of the default test data set -h (\u0026ndash;host=rdspg-fcj-labs.cssuddr073hp.us-east-1.rds.amazonaws.com): Specifies the hostname of the PostgreSQL server to connect to. -U (\u0026ndash;username=masteruser): Specifies the username to use to connect to the PostgreSQL server. pglab: The name of the database to create and populate. pgbench --host=rdspg-fcj-labs.cssuddr073hp.us-east-1.rds.amazonaws.com --username masteruser --protocol=prepared -P 30 --time=300 --client=200 --jobs=200 pglab -h (\u0026ndash;host=rdspg-fcj-labs.cssuddr073hp.us-east-1.rds.amazonaws.com): Specifies the hostname of the PostgreSQL server to connect to. -U (\u0026ndash;username masteruser): Specifies the username to use to connect to the PostgreSQL server. -p (\u0026ndash;protocol=prepared): Specifies that prepared statements should be used to execute the benchmark workload. \u0026ndash;progress (-P 30): Specifies that the benchmark should run for 30 seconds. -T (\u0026ndash;time=300): Specifies that the benchmark should run for 300 seconds. -c (\u0026ndash;client=200): Specifies that 200 concurrent client sessions should be used to execute the benchmark workload. -j (\u0026ndash;jobs=200): Specifies that 200 jobs should be created to execute the benchmark workload. pglab: The name of the database to create and populate. "
},
{
	"uri": "/9-cleanup/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": "\rPlease delete all resources and service that we have created for this lab before close your AWS console.\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]